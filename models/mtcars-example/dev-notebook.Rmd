---
title: "`mtcars` Example"
author: "Bilbo Baggins"
output: 
  html_document: 
    highlight: tango
    theme: journal
    toc: yes
    toc_float: true
---

```{r setup, include = FALSE, message = FALSE, results = 'hide', echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
model_name <- "mtcars-example"
k_path_project <- rprojroot::find_rstudio_root_file()
k_path_models <- file.path(k_path_project, "models")
k_path_mtcars <- file.path(k_path_models, model_name)
library(kableExtra)
library(foreach)
library(tidyverse)
```

## Synopsis {.tabset .tabset-fade}

### Introduction

This is a tutorial which explains how to develop a prediction model using the `rmonic` framwork.

Here, we fit a model to the [mtcars](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html) data set.

The target variable in mind is the miles per gallon, named **mpg**. Since miles is a non-negative numeric measurment, a regression prediction model is adequate. 

To stay focused on the `rmonic` framework, we use linear regression as the ML algorithm. 
In order to demonstrate how to use parameters in the modelling process, we employ a polynomial linear regression.

Finally, to evaluate the model performance, we use the {[rsample](https://tidymodels.github.io/rsample/)} package.

### Overview 

Under the `rmonic` framework, each model is composed of five function:

1. [model_init](#model_init) - Prepare everything the model needs
2. [model_fit](#model_fit) - Fit a model to training data
3. [model_predict](#model_predict) - Predict test data 
4. [model_store](#model_store) - Store the process iteration/epoch results 
5. [model_end](#model_end) - Performe some post-modelling operations

Depending on the need, you can create a new model or extend an existing model by calling *rmonic::create_model()* or *rmonic::extend_model()* respectively. 
These functions create a new folder with all the necessary components. 
The model's components are boilerplate, and the role of the data scientist is to 

(a) formulate an idea to a model, and 
(b) implement the idea using the components. 

For many applications, only the content of **model_fit** and **model_predict** varies between different models. This means the data scientist can go from model ideation to implementation quickly and focus the development efforts on what actually matters, rather than overhead.

### Model Workflow

1. When the model is launched: run `model_init()`
2. On each training data batch: 
a. Run `model_fit()` - Fit a model to training data
b. Run `model_predict()` - Predict test data
c. Run `model_store()` - Store the process iteration/epoch results 
3. Run `model_end()` - Perform some post-modelling operations

---

## Developing a Model {.tabset .tabset-fade}

### model_init {#model_init}

```{r model_init}
# Prepare everything the prediction model needs
model_init <- function(model_name){
    ###########################
    ## Defensive Programming ##
    ###########################
    ## Do not edit this part by hand
    assertive::assert_is_a_non_empty_string(model_name)
    ## Here you may add your assertions. Useful expressions include:
    ## * base::missing() - test whether a value was specified as a function arg
    ## * base::stopifnot() - for conditional statements to ensure code integrity
    ## * if(conditional statements) stop(<failure reason>)
    ## * {assertive} - informative check functions to ensure code integrity


    ###########
    ## Setup ##
    ###########
    ## Initialize the caching engine
    model_archive <<- file.path(k_path_cache, model_name)
    unlink(model_archive, recursive = TRUE, force = TRUE)
    archivist::createLocalRepo(model_archive, force = TRUE, default = TRUE)
    ## Get model's metadata from yaml file and make it available globally
    ## Note: model's metadata may contain parameters to pass into the model
    model_yaml <- rmonic::load_model_metadata(model_name, k_path_models)


    ######################
    ## Global Variables ##
    ######################
    ## Add model metadata parameters to the global environment
    list2env(model_yaml[["model_metadata"]], envir = .GlobalEnv)
    ## Other important variables
    ### Generate slug tags from the model metadata
    slug_model <<- compose_tags(model_yaml[["model_metadata"]])
    slug_model_fit <<- compose_tags(slug_model, source = "model_fit")
    slug_model_predict <<- compose_tags(slug_model, source = "model_predict")
    ### The sampled data split number
    split_num <<- 0
    ### The iteration number. k = 0, may signal that the model was not executed
    ### during an iterative process
    k <<- 0


    ##################
    ## Calculations ##
    ##################
    ## Here you may add your code


    ############
    ## Return ##
    ############
    ## Do not edit this part by hand
    return(invisible())
}
```

### model_fit {#model_fit}

```{r model_fit}
#' @title Fit One or More Models to a Training Set
#' @param training_set (`data.frame`) A table where samples are in rows and features are in columns.
# Fit one or more models to the data
model_fit <- function(training_set)
{
    ###########################
    ## Defensive Programming ##
    ###########################
    ## Do not edit this part by hand
    assertive::assert_has_rows(training_set)
    assertive::assert_all_are_existing(
        c("model_uid", "split_num", "unique_key_column", "model_archive"),
        envir = .GlobalEnv)
    ## Here you may add your assertions


    ###########
    ## Setup ##
    ###########
    # Remove the unique key column from the training set (to avoid overfitting)
    training_set <- training_set %>% select(-unique_key_column)
    # Compose the stage tag slug
    current_stage_tags <- rmonic::compose_tags(slug_model_fit, split = split_num)


    #########################
    ## Note for Developers ##
    #########################
    ##
    ## The prediction process, contains at least the following three parts:
    ## 1. Compose model metadata and store it in a JSON format
    ## 2. Fit model to the training data
    ## 3. Store the model and its metadata in a flat list
    ##
    ## Often, more than one model are created. If this is the case, you may:
    ## 1. Find a for loop a convenient implementation
    ## 2. Change the order of the aforementioned parts to suit your needs
    ##


    ###############
    ## Fit Model ##
    ###############
    model_object <- lm("MPG ~ .", training_set)


    ################################################
    ## Composing Metadata for the Model Fit Phase ##
    ################################################
    ##
    ## The following is a description of how to compose informative and valid
    ## metadata that describe model_fit outcome:
    ##
    ## 1. Metadata that extends the information available in the config.yml file
    ##    is passed via the model name. Examples for additional information are:
    ## (a) Split number. If some sampling schema is employed, say K-fold CV or
    ##     bootstrap, the split number alleviates post-processing operations.
    ## (b) The target variable (in case the same dataset has more than one
    ##     target variables, say predicting precipitation and wind-speed).
    ## (c) Grouping variables (in case the dataset is grouped by some variable,
    ##     say region).
    ##
    ## 2. Guidelines for composing a model name:
    ## (a) For the purpose of associating between a set of prediction and the
    ##     model which created it model_uid must be part of the model name.
    ## (b) The location of the different components in the name doesn't matter.
    ## (c) Each metadata must be a key-value pair. See details in
    ##     help(compose_model_name).
    ##
    model_tags <- rmonic::compose_tags(current_stage_tags, target_variable = "mpg")


    #############################
    ## Store Model in Database ##
    #############################
    rmonic::save_artifact(model_object, model_tags, model_archive)


    ############
    ## Return ##
    ############
    ## Do not edit this part by hand
    return(invisible())
}
```

### model_predict {#model_predict}

```{r model_predict}
#' @title Predict a Test Set Using Archived Models
#' @param test_set (`data.frame`) A table where samples are in rows and features are in columns.
model_predict <- function(test_set)
{
    ###########################
    ## Defensive Programming ##
    ###########################
    ## Do not edit this part by hand
    assertive::assert_has_rows(test_set)
    assertive::assert_all_are_existing(
        c("model_uid", "split_num", "unique_key_column", "model_archive"),
        envir = .GlobalEnv)
    ## Here you may add your assertions


    ###########
    ## Setup ##
    ###########
    # Compose stages tag slugs
    previous_stage_tags <- rmonic::compose_tags(slug_model_fit, split = split_num)
    current_stage_tags <- rmonic::compose_tags(slug_model_predict, split = split_num)


    ###################################
    ## Retrieve the Prediction Model ##
    ###################################
    ## Compose database query for the desiered model
    model_tags <- rmonic::compose_tags(previous_stage_tags, target_variable = "mpg")

    ## Retrieve the model
    model_object <- rmonic::load_artifact(model_tags, model_archive)


    ##########################
    ## Predict the Test Set ##
    ##########################
    response_vars <- predict(model_object, test_set, interval = "predict")
    rmonic::assert_objects_have_the_same_number_of_observations(response_vars, test_set)


    ###################################
    ## Store Predictions in Database ##
    ###################################
    ## Structure the prediction data in a key-value table
    uids <- test_set[,unique_key_column]
    y_fit <- rmonic::kv_table(key = uids, value = response_vars[,"fit"])
    y_upr <- rmonic::kv_table(key = uids, value = response_vars[,"upr"])
    y_lwr <- rmonic::kv_table(key = uids, value = response_vars[,"lwr"])
    ## Compose artifacts tags
    tags_fit <- compose_tags(current_stage_tags, response_type = "fit")
    tags_upr <- compose_tags(current_stage_tags, response_type = "upr")
    tags_lwr <- compose_tags(current_stage_tags, response_type = "lwr")
    ## Save prediction tables in database
    rmonic::save_artifact(y_fit, tags_fit, model_archive)
    rmonic::save_artifact(y_upr, tags_upr, model_archive)
    rmonic::save_artifact(y_lwr, tags_lwr, model_archive)


    ############
    ## Return ##
    ############
    ## Do not edit this part by hand
    return(invisible())
}
```

### model_store {#model_store}

```{r model_store}
# Log the results (predictions and model objects) in a concise and consistent manner
model_store <- function(){
    ###########################
    ## Defensive Programming ##
    ###########################
    ## Here you may add your assertions


    ############
    ## Return ##
    ############
    ## Do not edit this part by hand
    return(invisible())
}
```

### model_end {#model_end}

```{r model_end}
# Optional: Execute code after completion of backtesting
model_end <- function(){
    ###########################
    ## Defensive Programming ##
    ###########################
    ## Here you may add your assertions
    assertive::assert_all_are_existing(
        c("model_name", "slug_model", "model_archive"),
        envir = .GlobalEnv)


    #############################################
    ## Join the Predictions and their Metadata ##
    #############################################
    query <- rmonic::compose_tags(slug_model)
    predictions_full_table <-
        rmonic::retrieve_table(query, model_archive) %>% rmonic::standardize_col_names()
    predictions_long_table <-
        predictions_full_table %>% dplyr::select(RESPONSE_TYPE,SPLIT,KEY,VALUE)
    predictions_wide_table <-
        predictions_long_table %>% tidyr::spread(key = RESPONSE_TYPE, value = VALUE)


    ########################################################################
    ## Upload the Predictions to a Centralised Place for Further Analysis ##
    ########################################################################
    ##
    ## NOTE [@product-owner]:
    ## This function is defined by the product owner. By default, it assumes the
    ## first input argument is a predictions table where the:
    ## * 1st column contains the observations unique identifiers (UIDs). These
    ## values correspond to the UIDs of the original dataset identified prior to
    ## the modelling process. The UIDs link between the predictions table and
    ## the ground truth.
    ## * 2nd column contains non-negative prediction values.
    ##
    ## Collapse the table by observation id
    submission_data <-
        predictions_full_table %>%
        dplyr::filter(RESPONSE_TYPE %in% "fit") %>%
        dplyr::group_by(KEY) %>%
        dplyr::summarise(VALUE = mean(VALUE))
    ## Make a submission
    submit_predictions(artifact = submission_data, tags = slug_model)


    ############
    ## Return ##
    ############
    ## Do not edit this part by hand
    return(invisible())
}
```

<!-- Store Notebook Changes -->

```{r, echo = FALSE, results = 'hide'}
## Store notebook changes in model components.
## This means that the code above will take effect during model backtesting.
if(existsFunction("model_init")) 
    rmonic::write_function(model_init, file.path(k_path_mtcars, paste0("model_init.R")))
if(existsFunction("model_fit")) 
    rmonic::write_function(model_fit, file.path(k_path_mtcars, paste0("model_fit.R")))
if(existsFunction("model_predict")) 
    rmonic::write_function(model_predict, file.path(k_path_mtcars, paste0("model_predict.R")))
if(existsFunction("model_store")) 
    rmonic::write_function(model_store, file.path(k_path_mtcars, paste0("model_store.R")))
if(existsFunction("model_end")) 
    rmonic::write_function(model_end, file.path(k_path_mtcars, paste0("model_end.R")))
```

---

## Running the Model {.tabset .tabset-fade}

When all the model components and the configuration file are defined, we cascade
the modelling process between input and output stages.

1. **Input Interface** provides data ready for modelling. Often, it's the output
of a data pipeline that includes operations on the data such as transformations
and cleaning.
2. **Output Interface** controls the retention and disposal of artifacts
generated during the modelling process. It includes model objects and tables.
3. **Backtesting** is the intermediate layer between the input and output
interfaces. In its essence, this script fetches and executes the model code. It
uses historical data to assess how accurately the model would have predicted
actual results. In its core, there is a sampling schema, such as k-fold CV or
bootstrap, which is defined by the input interface.

For the completeness of the mtcars example, we provide two scripts under the
*helper-function* folder:

* "data_preparations.R" acts as the input interface; and
* "submit_predictions.R" acts as the output interface.

### Input Interface

```{r data_preparations, message=FALSE}
#' @title Load Data for Modelling
#'
#' @description load_data_for_modelling provides the data for the modelling
#'   stage.
#'
#' @details \code{rmonic} focal point is on the modelling process. Yet, to
#'   proceed with the modelling phase, a prior phase of preparing data for
#'   modelling is needed.
#'
#'   The data and the programming logic varies from one project to another.
#'   Therefore, it is not possible to generalize it to work
#'   out-of-the-rmonic-box. Instead, it is up to the product-owner/team-leader
#'   to define its content.
#'
#' @note: Using this function is one way of enabling the project data source for
#' modelling. In case you choose to use the function, here are some good
#' practices to increase reproducibility:
#'
#' \enumerate{
#'   \item Return an object created by \code{rsample}.
#'   \item Store the function in the project's shared function folder
#'   (i.e. \code{k_path_functions}).
#' }
#'
#' @return An object created by \code{rsample}.
#'
load_data_for_modelling <- function(){
    ##################
    ## Get the Data ##
    ##################
    ## Import the data
    dataset <- mtcars


    ########################
    ## Data Preprocessing ##
    ########################
    ## Standardise column names
    dataset <- dataset %>% rmonic::standardize_col_names()
    ## Set the unique key column
    unique_key_column <- "ROWID"
    ## Add a unique identifier such that each observation (row) is associated with
    ## a unique ID. Named it "ROWID".
    dataset <- dataset %>% tibble::rownames_to_column(var = unique_key_column)
    rownames(dataset) <- NULL


    ####################
    ## Split the Data ##
    ####################
    ## Option 1: Split the data to 70%/30% Training/Test sets
    # set.seed(902)
    # rset_obj <- rsample::initial_split(dataset, prop = 0.7)
    ## Option 2: K-fold cross validation
    set.seed(902)
    rset_obj <- rsample::vfold_cv(dataset, v = 5)
    ## Option 3: Bootstrap Sampling
    # set.seed(902)
    # rset_obj <- rsample::bootstraps(dataset, times = 20)


    ############
    ## Return ##
    ############
    return(rset_obj)
}
```

<!-- Store Notebook Changes -->

```{r, echo = FALSE, results = 'hide'}
## Store notebook changes under helper-functions.
## This means that the code above will take effect during model backtesting.
target <- file.path(k_path_mtcars, "helper-functions", paste0("load_data_for_modelling.R"))
if(existsFunction("load_data_for_modelling")) 
    rmonic::write_function(load_data_for_modelling, target)
```

### Output Interface

```{r submit_predictions, message=FALSE}
## submit_predictions
##
#' @title Upload the Predictions to a Centralised Place for Further Analysis
#'
#' @description Upload predictions and context about their creation to a
#'   centralised place. This allows further analysis including model evaluation
#'   and model comparison.
#'
#' @param artifact (`data.frame`) A predictions table with two columns:
#'
#' * 1st column, named KEY contains observations with unique identifiers. These
#' values correspond to the keys of the original dataset prior to the modelling
#' process. The keys link between the predictions table and the ground truth.
#'
#' * 2nd column, named VALUE, contains the predictions values.
#'
#' @param tags (`character`) A character vector with Tags. Each tag is a key-value pair in the following format "key:value". These Tags will be added to the repository along with the artifact. Tags can be easily assembled by \code{\link{compose_tags}}).
#'
#' @details This function is customised and defined by the product owner. Its
#'   programming logic is as follow:
#'
#' 1. The function checks the validity of the input arguments. If an assumption
#' is violated, such as KEY values are not unique, the function prompts an
#' informative error.
#'
#' 2. The function processes the data for submission.
#'
#' 3. The function uploads / stored the data and its context. The location and
#' technique are defined by the product owner.
#'
#' @section Note to Product Owner: To facilitate understanding between
#'   individual contributors, consider providing a \code{sample_submission.csv}
#'   file, say under \code{~/data/submissions}. This is as an example of what a
#'   submission file should look like. This file includes the structure of the
#'   anticipated predictions table. In the first column, KEY, it has the (real)
#'   observations unique identifiers. The other column(s), carry the name of the
#'   target variables. You may pad the empty cells with zeros, NAs or some
#'   benchmark model values.
#'
#' @return NULL
#'
submit_predictions <- function(artifact, tags){
    msgs <- "Uploading the predictions for further analysis"

    ###########################
    ## Defensive Programming ##
    ###########################
    ## Global variables existence
    assertive::assert_all_are_existing("k_path_submissions",
                                       envir = .GlobalEnv)
    ## Check if tags are valid
    invisible(rmonic::decompose_tags(tags))
    ## Check if artifact is a valid dataset
    assertive::assert_is_data.frame(artifact)
    stopifnot(ncol(data) == 2)
    ### 1st column
    if(artifact %>% select(+1) %>% is.na() %>% any()) stop("The 1st column contains NA values")
    assertive::assert_has_no_duplicates(artifact %>% select(+1))
    ### 2nd column and forward
    if(artifact %>% select(-1) %>% is.na() %>% any()) stop("The 2nd column contains NA values")
    assertive::assert_all_are_non_negative(artifact %>% select(-1) %>% as.matrix())


    ####################################
    ## Preprocess the Submission Data ##
    ####################################
    NULL


    #######################
    ## Make a Submission ##
    #######################
    if(rmonic::is_artifact_in_archive(artifact, k_path_submissions)){
        msg <- "\033[46mSubmission Skipped\033[49m"
        msg <- c(msg, "An identical submission was found in the archive.")

    } else {
        msg <- tryCatch({
            rmonic::save_artifact(artifact, tags, k_path_submissions)
            msg <- "\033[42mSubmission Successful\033[49m."
        }, error = function (e){
            msg <- "\033[41mSubmission Failed\033[49m."
            msg <- c(msg, e$message)
        }) # end tryCatch
    }# end if-else
    msgs <- c(msgs, msg)


    ############
    ## Return ##
    ############
    cat(msgs,  sep = "\n")
    return(invisible())
}
```

```{r, echo = FALSE, results = 'hide'}
## Store notebook changes under helper-functions.
## This means that the code above will take effect during model backtesting.
target <- file.path(k_path_mtcars, "helper-functions", paste0("submit_predictions.R"))
if(existsFunction("submit_predictions")) 
    rmonic::write_function(submit_predictions, target)
```

### Backesting

```{r model_backesting, message=FALSE, results=FALSE}
################################################################################
##                             Model Backtesting                              ##
################################################################################
#' WARNINGR:
#' Researching and backtesting is like drinking and driving.
#' Do not research under the influence of a backtest.
rmonic::setup()


####################
## Configurations ##
####################
## Define the model's name (must be identical to the model folder's name)
model_name <<- "mtcars-example"
### The column name which contains the identifiers of the data.frame rows
unique_key_column <<- "ROWID"


################
## Load Model ##
################
## Load model_init, model_fit, model_store, model_end located in model folder
rmonic::load_model_components(model_name, k_path_models)
## Load model helper functions located in model folder under helper-functions
rmonic::load_model_helper_functions(model_name, k_path_models)


#############################
## Load Data for Modelling ##
#############################
rset_obj <- load_data_for_modelling()


###############
## Run Model ##
###############
## Find out how many splits the rsample object contains
K <- rmonic::get_rsample_num_of_splits(rset_obj)

## Prepare everything our model needs
model_init(model_name)

## Loop over the dataset batches
list_of_bind_tables <- list()
for(k in 1:K) {
    ## Update global variables
    split_num <<- k

    ## Extract the current training set and test set from the rsample object
    training_set <- rmonic::get_rsample_training_set(rset_obj, k)
    test_set <- rmonic::get_rsample_test_set(rset_obj, k)

    ## Fit model(s) to the training set
    model_fit(training_set)

    ## Predict the test set
    model_predict(test_set)

    ## Store the results for further analysis
    model_store()
}# foreach-loop

## Post-modelling operations
model_end()
```

---

## Model Outcomes {.tabset .tabset-fade}

Backesting created two types of artifacts:

*  model objects - the product of *model_fit()*, and
*  prediction tables - the product of *model_predict()*.

Once backsting has been completed, we can query the archivist database for a
table with all the predictions and metadata about the context of their creation.
This is done by calling *retrieve_table()* with tags that constitute the
database query.

```{r full_table, echo=TRUE}
query <- rmonic::compose_tags("model_name" = "mtcars-example")
predictions_full_table <- rmonic::retrieve_table(query, model_archive) 
```

Below are three representations of the retrieved table:

1. **Full Table** is the retrieved table without any change.
2. **Wide Table** is a custom view that reports the prediction with their
prediction intervals.
3. **Submission Table** is the minimal viable (prediction) table. It collapses
data across attributes, such as *split*, into keys (observations IDS) and values
(predicted response).

### Full Table

The 'full table' comprises two column groups:

1. **Metadata** contains all the stored tags in the archive which are associated
with the table query.
    * In this example, we see that all the *model_metadata* fields in
    *config.mdl* appear, as we included this information in *slug_model* during
    [model_init](#model_init). Moreover, the context in which the predictions
    were made, such as *split* and *response_type*, appears as well.
    * Many of the columns are redundant, but some are useful. Having them allows
    us to:
        * Get to the bottom line. Regardless of the sampling schema, such as
        bootstrap or k-fold CV, we have sufficient information to summarise and
        pair prediction values with ids.
        * Scrutinise the results. There are numerous options to further analyse
        the results. Two aspects to consider are model-wise and
        observation-wise (in case bootstrap sampling was employed).
2. **Data** has the response values. It could sorce from one or more models, and
it could be one of different prediction types, such as lower/upper prediction
interval.

```{r, echo = FALSE}
predictions_full_table %>% 
    head() %>% 
    kable(digits = 2) %>% 
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                              full_width = TRUE,
                              position = "left",
                              font_size = 9) 
```

### Wide Table

```{r, echo = FALSE}
predictions_wide_table <- 
    predictions_full_table %>% 
    dplyr::select(response_type, split, KEY, VALUE) %>% 
    tidyr::spread(key = response_type, value = VALUE)

predictions_wide_table %>% 
    head(10) %>% 
    kable(digits = 2) %>% 
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                              full_width = TRUE,
                              position = "left",
                              font_size = 12) 
```

### Submission Table

```{r, echo = FALSE}
submission_data <-
    predictions_full_table %>%
    dplyr::filter(response_type %in% "fit") %>%
    dplyr::group_by(KEY) %>%
    dplyr::summarise(VALUE = mean(VALUE))

submission_data %>% 
    head(10) %>% 
    kable(digits = 2) %>% 
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                              full_width = FALSE,
                              position = "left",
                              font_size = 12) 
```

## Visualisation {.tabset .tabset-fade}

### Point Range

```{r, echo = FALSE, out.width = "100%"}
predictions_full_table %>% 
    dplyr::select(response_type, split, KEY, VALUE) %>% 
    tidyr::spread(key = response_type, value = VALUE) %>% 
    dplyr::group_by(KEY) %>% 
    dplyr::summarise(fit = mean(fit), lwr = mean(lwr), upr = mean(upr)) %>% 
    ggplot(aes(x = KEY, y = fit, ymin = lwr, ymax = upr)) +
    ylab("Miles per Gallon") +
    xlab("Car Model") +
    geom_pointrange() + 
    coord_flip()
```

### Box Plot

This plot is useful when bootstrap sampling is employed.

```{r, echo = FALSE, out.width = "100%"}
predictions_full_table %>% 
    filter(response_type %in% "fit") %>% 
    ggplot(aes(x = KEY, y = VALUE)) +
    ylab("Miles per Gallon") +
    xlab("Car Model") +
    geom_boxplot() + 
    coord_flip()
```
